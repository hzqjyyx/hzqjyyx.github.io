<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.4">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.4" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.0.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    fastclick: false,
    lazyload: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  
  <meta name="keywords" content="deeplearning," />


<meta name="description" content="Basic Idea  Connectionist Machine History Neural Network Model Perceptron Multi-layer Perceptron  as universal boolean function as universal classifier as universal approximator">
<meta name="keywords" content="deeplearning">
<meta property="og:type" content="article">
<meta property="og:title" content="Deep Learning:Introduction">
<meta property="og:url" content="https://hzqjyyx.github.io/2018/02/DL-Introduction/index.html">
<meta property="og:site_name" content="泽强的工作台">
<meta property="og:description" content="Basic Idea  Connectionist Machine History Neural Network Model Perceptron Multi-layer Perceptron  as universal boolean function as universal classifier as universal approximator">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/77lJJcl7Le.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/06GgjkEidh.jpg?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/7Kf2c2IH6A.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/K0afeg08fK.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/eJCl9A40Bd.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/l7Lf8cEdGj.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/JCiJk8iEf0.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/Cec09Hel9B.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/JJcdl02hG2.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/7gmbdajj0h.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/aj6e0KKib8.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/AaHG2K0Fe1.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/e0KjfHgIa8.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/Ae0Hcem6b6.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/jGIELDef35.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/5K3hbAjhbk.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/eFcDKLGLm5.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/4CCGf2cg64.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/5d8G6dc9j6.png?imageslim">
<meta property="og:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/626JgbDjGf.png?imageslim">
<meta property="og:updated_time" content="2018-02-24T03:47:47.025Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Learning:Introduction">
<meta name="twitter:description" content="Basic Idea  Connectionist Machine History Neural Network Model Perceptron Multi-layer Perceptron  as universal boolean function as universal classifier as universal approximator">
<meta name="twitter:image" content="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/77lJJcl7Le.png?imageslim">






  <link rel="canonical" href="https://hzqjyyx.github.io/2018/02/DL-Introduction/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>
  <title>Deep Learning:Introduction | 泽强的工作台</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">泽强的工作台</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">笔记/科研</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            Home</a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            About</a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            Tags</a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            Archives</a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            Search</a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hzqjyyx.github.io/2018/02/DL-Introduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="黄泽强（Zeqiang Huang)">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="泽强的工作台">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Deep Learning:Introduction</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-02-23T12:49:36-08:00">2018-02-23</time>
            

            
            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/02/DL-Introduction/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/02/DL-Introduction/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2018/02/DL-Introduction/" class="leancloud_visitors" data-flag-title="Deep Learning:Introduction">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Views&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="basic-idea"><a class="markdownIt-Anchor" href="#basic-idea"></a> Basic Idea</h1>
<ul>
<li>Connectionist Machine</li>
<li>History Neural Network Model</li>
<li>Perceptron</li>
<li>Multi-layer Perceptron
<ul>
<li>as universal boolean function</li>
<li>as universal classifier</li>
<li>as universal approximator</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h1 id="introduction"><a class="markdownIt-Anchor" href="#introduction"></a> Introduction</h1>
<h2 id="models"><a class="markdownIt-Anchor" href="#models"></a> Models</h2>
<h3 id="early-association"><a class="markdownIt-Anchor" href="#early-association"></a> Early: Association</h3>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/77lJJcl7Le.png?imageslim" alt="mark"></p>
<p>We memorize and rationalize through association</p>
<p><strong>Aristotle’s four laws of association</strong>:</p>
<ul>
<li><strong>The law of contiguity.</strong>  Things or events that occur close together in space or time get linked together</li>
<li><strong>The law of frequency.</strong>  The more often two things or events are linked, the more powerful that association.</li>
<li><strong>The law of similarity.</strong>  If two things are similar, the thought of one will trigger the thought of the other</li>
<li><strong>The law of contrast.</strong> Seeing or recalling something may trigger the recollection of something opposite</li>
</ul>
<p><strong>But do not mention how to store the connection</strong></p>
<h3 id="connectionist-machines"><a class="markdownIt-Anchor" href="#connectionist-machines"></a> Connectionist Machines</h3>
<p>All world knowledge is stored in the connections between the elements. The workings  of the brain are encoded in these connections.<br>
Network of processing elements<br>
Multiple connectionist paradigms proposed</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/06GgjkEidh.jpg?imageslim" alt="mark"></p>
<h3 id="turings-connectionist-machine"><a class="markdownIt-Anchor" href="#turings-connectionist-machine"></a> Turing’s Connectionist Machine</h3>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/7Kf2c2IH6A.png?imageslim" alt="mark"></p>
<h2 id="single-neuron-for-boolean-functions"><a class="markdownIt-Anchor" href="#single-neuron-for-boolean-functions"></a> Single Neuron For Boolean Functions</h2>
<p>A few  methods that models brain which is a connectionist machine.<br>
For now, we take a look at individual elements.</p>
<h3 id="the-mcculloch-and-pitts-model"><a class="markdownIt-Anchor" href="#the-mcculloch-and-pitts-model"></a> The McCulloch and Pitts model</h3>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/K0afeg08fK.png?imageslim" alt="mark"></p>
<p>The activity of the neuron is an ‘‘all-or-none’’ process</p>
<p>A <strong>certain fixed number</strong> of synapses must be excited within the period of latent addition in order to excite a neuron at any time</p>
<p>Could compute <strong>arbitrary</strong> Boolean propositions.</p>
<p><strong>Didn’t provide a learning mechanism</strong>. Cannot change connection. It is just a state machine</p>
<p><strong>Examples</strong></p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/eJCl9A40Bd.png?imageslim" alt="mark"></p>
<h3 id="hebbian-learning"><a class="markdownIt-Anchor" href="#hebbian-learning"></a> Hebbian Learning</h3>
<p>If neuron repeatedly triggers neuron , the synaptic knob connecting to gets larger.</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>W</mi><mi>i</mi></msub><mo>=</mo><msub><mi>W</mi><mi>i</mi></msub><mo>+</mo><mi>η</mi><msub><mi>x</mi><mi>i</mi></msub><mi>y</mi></mrow><annotation encoding="application/x-tex">W_i = W_i+\eta x_i y
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.8777699999999999em;vertical-align:-0.19444em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.13889em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.03588em;">η</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathit" style="margin-right:0.03588em;">y</span></span></span></span></span></p>
<p>But unlucky, every connection get stronger, no reduction in weights. It would not learn anything (every output would be ‘1’). <strong>Unstable</strong>.</p>
<h3 id="rosenblatts-perceptron"><a class="markdownIt-Anchor" href="#rosenblatts-perceptron"></a> Rosenblatt’s perceptron</h3>
<p>A variant of the McCulloch and Pitt neuron with a provably convergent learning rule<br>
Original perceptron model. Number of inputs combine linearly.<br>
Threshold logic:  <strong>Fire</strong> if combined input exceeds <strong>threshold</strong></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>f</mi><mo>(</mo><mi>n</mi><mo>)</mo><mo>=</mo><mrow><mo fence="true">{</mo><mtable><mtr><mtd><mrow><mn>1</mn></mrow></mtd><mtd><mrow><mspace width="1em"></mspace><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">f</mi><mtext> </mtext></mtext><msub><mo>∑</mo><mi>N</mi></msub><mrow><msub><mi>w</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub></mrow><mo>−</mo><mi>T</mi><mo>&gt;</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn></mrow></mtd><mtd><mrow><mspace width="1em"></mspace><mtext><mi mathvariant="normal">e</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi></mtext></mrow></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">f(n) =
  \begin{cases}
    1       &amp; \quad \text{if } \sum_N{w_i x_i} - T &gt; 0\\
    0  &amp; \quad \text{else}
  \end{cases}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:2.1421704999999998em;"></span><span class="strut bottom" style="height:3.784341em;vertical-align:-1.6421705000000002em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathit">n</span><span class="mclose">)</span><span class="mrel">=</span><span class="minner displaystyle textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped"><span class="delimsizing mult"><span class="vlist"><span style="top:0.65001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size4"><span>⎩</span></span></span><span style="top:-0.000010000000000065512em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size4"><span>⎨</span></span></span><span style="top:-1.15002em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="delimsizinginner delim-size4"><span>⎧</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist"><span style="top:-1.0921654999999995em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">1</span></span></span><span style="top:1.2101705000000003em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">0</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist"><span style="top:-1.0921654999999995em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord mspace quad"></span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">i</span><span class="mord mathrm" style="margin-right:0.07778em;">f</span><span class="mord mspace"> </span></span><span class="mop op-limits"><span class="vlist"><span style="top:1.1943359999999998em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.10903em;">N</span></span></span><span style="top:-0.000005000000000143778em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span><span class="op-symbol large-op mop">∑</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.02691em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.13889em;">T</span><span class="mrel">&gt;</span><span class="mord mathrm">0</span></span></span><span style="top:1.2101705000000003em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord mspace quad"></span><span class="text mord displaystyle textstyle uncramped"><span class="mord mathrm">e</span><span class="mord mathrm">l</span><span class="mord mathrm">s</span><span class="mord mathrm">e</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span></span></p>
<p><strong>Learning algorithm</strong></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>=</mo><mi>w</mi><mo>+</mo><mi>η</mi><mo>(</mo><mi>d</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>−</mo><mi>y</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>)</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">w=w+\eta(d(x)-y(x))x
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.03588em;">η</span><span class="mopen">(</span><span class="mord mathit">d</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mclose">)</span><span class="mord mathit">x</span></span></span></span></span></p>
<ul>
<li>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">d(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">d</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> is the desired output in response to input <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span></p>
</li>
<li>
<p><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>y</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">y(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> is the actual output in response to <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">x</span></span></span></span></p>
</li>
</ul>
<p>Solve Boolean tasks<br>
Update the weights whenever the perceptron output is wrong<br>
Proved convergence</p>
<p>But, it cannot solve XOR problem. Individual elements are weak computational elements, and networked elements are required</p>
<h2 id="perceptron"><a class="markdownIt-Anchor" href="#perceptron"></a> Perceptron</h2>
<h3 id="what-perceptron-really-models"><a class="markdownIt-Anchor" href="#what-perceptron-really-models"></a> What perceptron really models</h3>
<p>Weights, behaves as a “template”.</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/l7Lf8cEdGj.png?imageslim" alt="mark"></p>
<p>The perceptron fires if the input is <strong>within</strong> a specified angle of the weight. In other words, Neuron fires if the input  vector is close enough to the weight vector. In other other words,  If the input pattern matches the weight pattern closely enough.</p>
<p>Thus, the input layer comprises “feature detectors” . Detect if certain patterns have occurred in the input. Also, the network is a cascade of feature detectors. Higher level neurons compose complex templates from features represented by lower-level neurons.</p>
<h3 id="perceptron-with-real-inputs"><a class="markdownIt-Anchor" href="#perceptron-with-real-inputs"></a> Perceptron with real inputs</h3>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/JCiJk8iEf0.png?imageslim" alt="mark"></p>
<p>Sometimes outputs are viewed as the “probability” of firing.</p>
<p>Any real-valued “activation” function may operate on the weighted sum input.<br>
In this way, we extend the original definition of perceptron from Boolean to Real.</p>
<h3 id="applied-to-complicated-decision-boundary"><a class="markdownIt-Anchor" href="#applied-to-complicated-decision-boundary"></a> Applied to complicated “decision boundary”</h3>
<p>A perceptron operates on real-valued vectors act as a <strong>linear classifier</strong>, which is correspondent to a line in plane (assuming input is 2D), applying a ‘hard’ <strong>threshold</strong>.</p>
<p>Can compose very complex decision boundaries</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/Cec09Hel9B.png?imageslim" alt="mark"></p>
<p><strong>However, it cannot model two separated decision boundary.</strong></p>
<h1 id="multi-layer-perception"><a class="markdownIt-Anchor" href="#multi-layer-perception"></a> Multi-layer Perception</h1>
<h2 id="mlps-as-universal-boolean-functions"><a class="markdownIt-Anchor" href="#mlps-as-universal-boolean-functions"></a> MLPs as universal Boolean functions</h2>
<h3 id="simple-mlp"><a class="markdownIt-Anchor" href="#simple-mlp"></a> Simple MLP</h3>
<p>Could mimic XOR<br>
Can compose arbitrarily complicated Boolean functions</p>
<hr>
<p>Let’s first think about output is boolean.</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/JJcdl02hG2.png?imageslim" alt="mark"></p>
<p>Network to fire if the input is in the yellow area</p>
<ul>
<li>“OR” two polygons</li>
<li>A third layer is required</li>
</ul>
<p><strong>In summary</strong></p>
<ul>
<li>MLPs(Multi-layer Perceptron) are connectionist computational models
<ul>
<li>Individual perceptrons are computational equivalent of neurons</li>
<li>The MLP is a layered composition of many perceptrons</li>
</ul>
</li>
<li>MLPs can model Boolean functions
<ul>
<li>Individual perceptrons can act as Boolean gates</li>
<li>Networks of perceptrons are  Boolean functions</li>
</ul>
</li>
<li>MLPs are Boolean machines
<ul>
<li>They represent Boolean functions over linear boundaries</li>
<li>They can represent arbitrary  decision boundaries</li>
<li>They can be used to classify data</li>
</ul>
</li>
</ul>
<h3 id="how-well-do-mlps-model-boolean-functions"><a class="markdownIt-Anchor" href="#how-well-do-mlps-model-boolean-functions"></a> How well do MLPs model Boolean functions?</h3>
<p>A perceptron can model <strong>AND, OR, NOT</strong>.<br>
A perceptron can model <strong>universal AND, universal OR</strong>.<br>
A perceptron can <strong>NOT</strong> model <strong>XOR</strong>, but MLPs can.</p>
<p>MLPs are <strong>universal Boolean functions</strong> – Any function over any number of inputs and any number of outputs. Even a single hidden layer network</p>
<h3 id="but-how-many-layers-will-they-need"><a class="markdownIt-Anchor" href="#but-how-many-layers-will-they-need"></a> But how many “layers” will they need?</h3>
<h4 id="one-hidden-layer-is-enough"><a class="markdownIt-Anchor" href="#one-hidden-layer-is-enough"></a> One-hidden-layer is enough</h4>
<p>A Boolean function is just a truth table.</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/7gmbdajj0h.png?imageslim" alt="mark"></p>
<p>Any truth table can be expressed in this manner!<br>
<u>A one-hidden-layer MLP is a Universal Boolean Function</u></p>
<h4 id="largest-number-of-perceptrons-required-in-one-hidden-layer"><a class="markdownIt-Anchor" href="#largest-number-of-perceptrons-required-in-one-hidden-layer"></a> Largest number of perceptrons required in One-hidden-layer</h4>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/aj6e0KKib8.png?imageslim" alt="mark"></p>
\text{Required } 2^{N-1} \text{ perceptrons}\\
\text{Required } O(N2^{N-1}) \text{ weights}

<h4 id="how-many-units-if-use-multiple-layers"><a class="markdownIt-Anchor" href="#how-many-units-if-use-multiple-layers"></a> How many units if use multiple layers</h4>
<p><strong>Build upon single linked XOR</strong></p>
<p>Kind of deepest network for a certain input</p>
<p>An XOR needs 3 perceptrons, 9 parameters.<br>
An <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">n</span></span></span></span> input network needs <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn><mo>(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">3(N-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">3</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mbin">−</span><span class="mord mathrm">1</span><span class="mclose">)</span></span></span></span> perceptrons, <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>9</mn><mo>(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo>)</mo></mrow><annotation encoding="application/x-tex">9(N-1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">9</span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mbin">−</span><span class="mord mathrm">1</span><span class="mclose">)</span></span></span></span> parameters, N layers.</p>
<p>Also, a better representation needs <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mi>l</mi><mi>o</mi><msub><mi>g</mi><mn>2</mn></msub><mo>(</mo><mi>N</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">2log_2(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span> layers, but requires same perceptrons.</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/AaHG2K0Fe1.png?imageslim" alt="mark"></p>
<p>Using only K hidden layers will require <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mn>2</mn><mrow><mi>C</mi><mi>N</mi></mrow></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(2^{CN})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8413309999999999em;"></span><span class="strut bottom" style="height:1.0913309999999998em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mord mathit" style="margin-right:0.10903em;">N</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span> neurons in the Kth layer, where <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>=</mo><msup><mn>2</mn><mrow><mo>−</mo><mi>k</mi><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup></mrow><annotation encoding="application/x-tex">C=2^{-k/2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mrel">=</span><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord">−</span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mord mathrm">/</span><span class="mord mathrm">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></p>
<ul>
<li>Because the output can be shown to be the XOR of all the outputs of the K-1th hidden layer</li>
<li>I.e. reducing the number of layers below the minimum will result in an exponentially sized network to express the function fully</li>
<li>A network with fewer than the minimum required number of neurons cannot model the function, but can approximate.</li>
</ul>
<p><strong>In short</strong></p>
<p>Having a few extra layers can greatly reduce network size.<br>
Network can become <strong>exponentially</strong> large if recast using only one layer</p>
<h4 id="depth-vs-size-in-boolean-circuits"><a class="markdownIt-Anchor" href="#depth-vs-size-in-boolean-circuits"></a> Depth vs Size in Boolean Circuits</h4>
<p>An <em>unbounded fan-in</em> circuit, is a circuit with no limitation on the fan-in of its AND and OR gates.</p>
<p>Any Boolean circuit of depth <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">d</span></span></span></span> using AND,OR and NOT gates with unbounded fan-in must have size <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mn>2</mn><mrow><msup><mi>n</mi><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mi>d</mi></mrow></msup></mrow></msup></mrow><annotation encoding="application/x-tex">2^{n^{1/d}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9921em;"></span><span class="strut bottom" style="height:0.9921em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathrm">2</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:-0.363em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle uncramped"><span class="mord scriptscriptstyle uncramped"><span class="mord mathrm">1</span><span class="mord mathrm">/</span><span class="mord mathit">d</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>.</p>
<p>Caveat:</p>
<ul>
<li>Not all Boolean circuits have such clear depth-vs-size tradeoff</li>
<li>We do not apply the power of threshold circuit (TC)
<ul>
<li>For fixed depth, Boolean circuits ⊂ 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑 𝑐𝑖𝑟𝑐𝑢𝑖𝑡𝑠 (strict subset)</li>
</ul>
</li>
</ul>
<h4 id="network-size-summary"><a class="markdownIt-Anchor" href="#network-size-summary"></a> Network size summary</h4>
<p>An MLP is a universal Boolean function. But can represent a given function only if</p>
<ul>
<li>It is sufficiently wide</li>
<li>It is sufficiently deep</li>
<li>Depth can be traded off for (sometimes) exponential growth of the width of the network</li>
</ul>
<p>Optimal width and depth depend on the number of variables and the complexity of the Boolean function</p>
<ul>
<li>Complexity:  minimal number of terms in DNF formula to represent it</li>
</ul>
<h4 id="summary"><a class="markdownIt-Anchor" href="#summary"></a> Summary</h4>
<ul>
<li>Multi-layer perceptrons are Universal Boolean Machines</li>
<li>Even a network with a single hidden layer is a universal Boolean machine
<ul>
<li>But a single-layer network may require an exponentially large number of perceptrons</li>
</ul>
</li>
<li>Deeper networks may require far fewer neurons than shallower networks to express the same function
<ul>
<li>Could be exponentially smaller</li>
</ul>
</li>
</ul>
<h2 id="mlps-as-universal-classifiers"><a class="markdownIt-Anchor" href="#mlps-as-universal-classifiers"></a> MLPs as universal classifiers</h2>
<blockquote>
<p>The need for depth</p>
<p>MLP as a function over real inputs<br>
MLP as a function that finds a complex “decision boundary” over a space of reals</p>
</blockquote>
<h3 id="mlp-as-a-continuous-valued-regression"><a class="markdownIt-Anchor" href="#mlp-as-a-continuous-valued-regression"></a> MLP as a continuous-valued regression</h3>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/e0KjfHgIa8.png?imageslim" alt="mark"></p>
<p>An MLP with many units can model an arbitrary function over an input to arbitrary precision.</p>
<p>A single input can create 1D line, and two inputs can create 2D graph.</p>
<p>Perceptrons are correlation filters.<br>
They detect patterns in the input. A single input represents a 1D function</p>
<p><strong>More general</strong></p>
<p>MLPs are classification engines</p>
<ul>
<li>They can identify classes in the data</li>
<li>Individual perceptrons are feature detectors</li>
<li>The network will fire if the combination of  the detected basic features matches an “acceptable” pattern for a desired class of signal</li>
<li>Interesting AI tasks are functions that can be modelled by the network</li>
</ul>
<p>A perceptron is a linear classifier<br>
MLPs can capture any classification boundary<br>
A <strong>one-layer</strong> MLP can model any classification boundary<br>
MLPs are universal classifiers</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/Ae0Hcem6b6.png?imageslim" alt="mark"></p>
<h3 id="optimal-depth"><a class="markdownIt-Anchor" href="#optimal-depth"></a> Optimal depth</h3>
<p>Formal analyses typically view these as category of arithmetic circuits.<br>
A polynomial of degree n requires a network of depth <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><msup><mi>g</mi><mn>2</mn></msup><mo>(</mo><mi>n</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">log^2(n)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">o</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">g</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit">n</span><span class="mclose">)</span></span></span></span></p>
<p><strong>Sum-product nets</strong><br>
For networks where layers alternately perform either sums or products, a deep network may require an <strong>exponentially</strong> fewer number of layers than a shallow one.</p>
<p><strong>generic nets</strong></p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/jGIELDef35.png?imageslim" alt="mark"></p>
<h4 id="network-size"><a class="markdownIt-Anchor" href="#network-size"></a> Network size</h4>
<p>In this problem the 2-layer net was quadratic(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>n</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(n^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span>) in the number of lines. The pattern is exponential in the dimension of the input (two)!</p>
<p>For general case of mutually intersecting hyperplanes in D dimensions, we will need <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>O</mi><mo>(</mo><mfrac><mrow><msup><mi>N</mi><mi>D</mi></msup></mrow><mrow><mo>(</mo><mi>D</mi><mo>−</mo><mn>1</mn><mo>)</mo><mo>!</mo></mrow></mfrac><mo>)</mo></mrow><annotation encoding="application/x-tex">O(\frac{N^D}{(D-1)!})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9897649999999999em;"></span><span class="strut bottom" style="height:1.5097649999999998em;vertical-align:-0.52em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord reset-textstyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.34500000000000003em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">D</span><span class="mbin">−</span><span class="mord mathrm">1</span><span class="mclose">)</span><span class="mclose">!</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="vlist"><span style="top:-0.363em;margin-right:0.07142857142857144em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">D</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mclose">)</span></span></span></span> weights (assuming N &gt;&gt; D).</p>
<ul>
<li>Increasing input dimensions can increase the worst-case size of the shallower network exponentially, but not the XOR net</li>
<li>The size of the XOR net depends only on the number of first-level linear detectors (𝑁)</li>
</ul>
<p>The number of neurons required in a shallow network is potentially exponential in the dimensionality of the input.</p>
<h2 id="mlps-as-universal-approximator"><a class="markdownIt-Anchor" href="#mlps-as-universal-approximator"></a> MLPs as universal approximator</h2>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/5K3hbAjhbk.png?imageslim" alt="mark"></p>
<p>MLPs can actually compose arbitrary functions in any number of dimensions!</p>
<ul>
<li>Even with only one layer (That’s why we use CNN to introduce invariant)
<ul>
<li>As sums of scaled and shifted cylinders</li>
</ul>
</li>
<li>To arbitrary precision
<ul>
<li>By making the cylinders thinner</li>
</ul>
</li>
<li>The MLP is a universal approximator!</li>
</ul>
<h3 id="outputs-with-activation"><a class="markdownIt-Anchor" href="#outputs-with-activation"></a> Outputs with activation</h3>
<p>The network is actually a map from the set of all possible input values to all possible output values – All values the activation function of the output neuron.</p>
<p>The MLP is a Universal Approximator for the entire class of functions (maps) it represents!</p>
<h2 id="optimal-depth-and-width"><a class="markdownIt-Anchor" href="#optimal-depth-and-width"></a> Optimal depth and width</h2>
<h3 id="depth"><a class="markdownIt-Anchor" href="#depth"></a> Depth</h3>
<p>In any directed network of computational elements with input source nodes and output sink nodes, “depth” is the length of the longest path from a source to a sink</p>
<p>Which means: count(hidden layer)+1</p>
<p><strong>Deep:</strong> Depth &gt; 2</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/eFcDKLGLm5.png?imageslim" alt="mark"></p>
<h3 id="sufficiency-of-architecture"><a class="markdownIt-Anchor" href="#sufficiency-of-architecture"></a> Sufficiency of architecture</h3>
<p>A neural network can represent any function provided it has sufficient capacity – I.e. sufficiently broad and deep to represent the function.<br>
Not all architectures can represent any functions.</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/4CCGf2cg64.png?imageslim" alt="mark"></p>
<p>But, this effect is because we use the threshold activation. It gates information in the input from later layers. Subsequent layers do not obtain enough information to partition them.</p>
<p>Continuous activation functions result in graded output at the layer.<br>
The gradation provides information to subsequent layers, to capture information “missed” by the lower layer (i.e. it “passes” information to subsequent layers).<br>
Activations with more gradation (e.g. <strong>RELU</strong>) pass more information.</p>
<p>A network with insufficient capacity cannot exactly model a function that requires a greater minimal number of convex hulls than the capacity of the network.<br>
But can <strong>approximate</strong> it with error.</p>
<h4 id="width-vs-activations-vs-depth"><a class="markdownIt-Anchor" href="#width-vs-activations-vs-depth"></a> Width vs. Activations vs. Depth</h4>
<ul>
<li>Narrow layers can still pass information to subsequent layers if the activation function is sufficiently graded.</li>
<li>But will require greater depth, to permit later layers to capture patterns.</li>
</ul>
<h2 id="rbf-networks"><a class="markdownIt-Anchor" href="#rbf-networks"></a> RBF networks</h2>
<blockquote>
<p>Radial Basis Functions</p>
</blockquote>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/5d8G6dc9j6.png?imageslim" alt="mark"></p>
<p>The output is a function of the distance of the input from a “center”</p>
<ul>
<li>The “center” is the parameter specifying the unit</li>
<li>The most common activation is the exponent
<ul>
<li>𝛽 is a “bandwidth” parameter</li>
</ul>
</li>
<li>But other similar activations may also be used
<ul>
<li>Key aspect is radial symmetry, instead of linear symmetry</li>
</ul>
</li>
</ul>
<p>Radial basis functions can compose cylinder-like outputs with just a single unit with appropriate choice of bandwidth (or activation function)</p>
<p>RBF networks are more effective approximators of continuous-valued functions<br>
A one-hidden-layer net only requires one unit per “cylinder”.</p>
<h1 id="appendix"><a class="markdownIt-Anchor" href="#appendix"></a> Appendix</h1>
<h2 id="threshold-vs-sigmoid"><a class="markdownIt-Anchor" href="#threshold-vs-sigmoid"></a> Threshold VS Sigmoid</h2>
<p>Demo</p>
<p><img src="http://o9bjjf9jh.bkt.clouddn.com/blog/180223/626JgbDjGf.png?imageslim" alt="mark"></p>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/deeplearning/" rel="tag"># deeplearning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/Github Open Source for Android Dev/" rel="next" title="Open Source for Android Dev (Part I)">
                <i class="fa fa-chevron-left"></i> Open Source for Android Dev (Part I)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/02/DL-Learning the network/" rel="prev" title="Deep Learning: Learning the network">
                Deep Learning: Learning the network <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">黄泽强（Zeqiang Huang)</p>
              <p class="site-description motion-element" itemprop="description">笔记/科研</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">12</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/hzqjyyx" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
            </div>
          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#basic-idea"><span class="nav-number">1.</span> <span class="nav-text"> Basic Idea</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#introduction"><span class="nav-number">2.</span> <span class="nav-text"> Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#models"><span class="nav-number">2.1.</span> <span class="nav-text"> Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#early-association"><span class="nav-number">2.1.1.</span> <span class="nav-text"> Early: Association</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#connectionist-machines"><span class="nav-number">2.1.2.</span> <span class="nav-text"> Connectionist Machines</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#turings-connectionist-machine"><span class="nav-number">2.1.3.</span> <span class="nav-text"> Turing’s Connectionist Machine</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#single-neuron-for-boolean-functions"><span class="nav-number">2.2.</span> <span class="nav-text"> Single Neuron For Boolean Functions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#the-mcculloch-and-pitts-model"><span class="nav-number">2.2.1.</span> <span class="nav-text"> The McCulloch and Pitts model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hebbian-learning"><span class="nav-number">2.2.2.</span> <span class="nav-text"> Hebbian Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rosenblatts-perceptron"><span class="nav-number">2.2.3.</span> <span class="nav-text"> Rosenblatt’s perceptron</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#perceptron"><span class="nav-number">2.3.</span> <span class="nav-text"> Perceptron</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#what-perceptron-really-models"><span class="nav-number">2.3.1.</span> <span class="nav-text"> What perceptron really models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#perceptron-with-real-inputs"><span class="nav-number">2.3.2.</span> <span class="nav-text"> Perceptron with real inputs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#applied-to-complicated-decision-boundary"><span class="nav-number">2.3.3.</span> <span class="nav-text"> Applied to complicated “decision boundary”</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#multi-layer-perception"><span class="nav-number">3.</span> <span class="nav-text"> Multi-layer Perception</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#mlps-as-universal-boolean-functions"><span class="nav-number">3.1.</span> <span class="nav-text"> MLPs as universal Boolean functions</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#simple-mlp"><span class="nav-number">3.1.1.</span> <span class="nav-text"> Simple MLP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#how-well-do-mlps-model-boolean-functions"><span class="nav-number">3.1.2.</span> <span class="nav-text"> How well do MLPs model Boolean functions?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#but-how-many-layers-will-they-need"><span class="nav-number">3.1.3.</span> <span class="nav-text"> But how many “layers” will they need?</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#one-hidden-layer-is-enough"><span class="nav-number">3.1.3.1.</span> <span class="nav-text"> One-hidden-layer is enough</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#largest-number-of-perceptrons-required-in-one-hidden-layer"><span class="nav-number">3.1.3.2.</span> <span class="nav-text"> Largest number of perceptrons required in One-hidden-layer</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#how-many-units-if-use-multiple-layers"><span class="nav-number">3.1.3.3.</span> <span class="nav-text"> How many units if use multiple layers</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#depth-vs-size-in-boolean-circuits"><span class="nav-number">3.1.3.4.</span> <span class="nav-text"> Depth vs Size in Boolean Circuits</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#network-size-summary"><span class="nav-number">3.1.3.5.</span> <span class="nav-text"> Network size summary</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#summary"><span class="nav-number">3.1.3.6.</span> <span class="nav-text"> Summary</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mlps-as-universal-classifiers"><span class="nav-number">3.2.</span> <span class="nav-text"> MLPs as universal classifiers</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mlp-as-a-continuous-valued-regression"><span class="nav-number">3.2.1.</span> <span class="nav-text"> MLP as a continuous-valued regression</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#optimal-depth"><span class="nav-number">3.2.2.</span> <span class="nav-text"> Optimal depth</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#network-size"><span class="nav-number">3.2.2.1.</span> <span class="nav-text"> Network size</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mlps-as-universal-approximator"><span class="nav-number">3.3.</span> <span class="nav-text"> MLPs as universal approximator</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#outputs-with-activation"><span class="nav-number">3.3.1.</span> <span class="nav-text"> Outputs with activation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#optimal-depth-and-width"><span class="nav-number">3.4.</span> <span class="nav-text"> Optimal depth and width</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#depth"><span class="nav-number">3.4.1.</span> <span class="nav-text"> Depth</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sufficiency-of-architecture"><span class="nav-number">3.4.2.</span> <span class="nav-text"> Sufficiency of architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#width-vs-activations-vs-depth"><span class="nav-number">3.4.2.1.</span> <span class="nav-text"> Width vs. Activations vs. Depth</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#rbf-networks"><span class="nav-number">3.5.</span> <span class="nav-text"> RBF networks</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#appendix"><span class="nav-number">4.</span> <span class="nav-text"> Appendix</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#threshold-vs-sigmoid"><span class="nav-number">4.1.</span> <span class="nav-text"> Threshold VS Sigmoid</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">黄泽强（Zeqiang Huang)</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Gemini</a> v6.0.4</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>







  






  















  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.4"></script>



  

  
    <script id="dsq-count-scr" src="https://hzqjyyx.disqus.com/count.js" async></script>
  

  
    <script type="text/javascript">
      var disqus_config = function () {
        this.page.url = 'https://hzqjyyx.github.io/2018/02/DL-Introduction/';
        this.page.identifier = '2018/02/DL-Introduction/';
        this.page.title = 'Deep Learning:Introduction';
      };
      function loadComments () {
        var d = document, s = d.createElement('script');
        s.src = 'https://hzqjyyx.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      }
      
        loadComments();
      
    </script>
  





	





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("ebkw82HKvG8gVHMVNdhYwTXH-gzGzoHsz", "HHUiCQCiKnzUn96uwRxbES4x");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  

  
    
      <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex@0.7.1/dist/katex.min.css" type="text/css">

   
  


  
  

  

  

  

  

</body>
</html>
